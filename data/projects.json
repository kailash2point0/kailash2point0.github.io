{
  "projects": [
    {
      "pid": "26",
      "seededIn": "2021",
      "shortName": "SPS",
      "longName": "Smart Parking System",
      "duration": "Sept 2021 - Nov 2021",
      "shortDesc": "Vision based system using object detection through ESP32-CAMs, Raspberry Pi and cloud deployed NodeJS web-server.",
      "longDesc": [
        {
          "heading": "",
          "type": "para",
          "para": "Parking has always been an issue in metropolitan cities. Be it a shopping complex or a public arena, parking wastes time and fuel, and sometimes one must break a sweat to get it done. This calls for a streamlined approach through which people can easily find and park their vehicles close to their destinations."
        },
        {
          "heading": "",
          "type": "bullets",
          "para": [
            "Our Smart Parking System (SPS) uses low-cost camera modules installed at multiple parking lots across the city and streams live images to the corresponding remote server. The remote server processes the data from the camera module and decides on the number of vacant parking spaces available in the parking lot. ",
            "Our Smart Parking System (SPS) uses low-cost camera modules installed at multiple parking lots across the city and streams live images to the corresponding remote server. The remote server processes the data from the camera module and decides on the number of vacant parking spaces available in the parking lot. ",
            "Our Smart Parking System (SPS) uses low-cost camera modules installed at multiple parking lots across the city and streams live images to the corresponding remote server. The remote server processes the data from the camera module and decides on the number of vacant parking spaces available in the parking lot. "
          ]
        },
        {
          "heading": "",
          "para": "The remote server updates the number of vacant and filled parking slots in a cloud database. The number of vacant parking slots and their location are displayed in a web application accessible to the general public and free to use. The database is updated continuously, ensuring a pristine user experience. "
        }
      ],
      "techStack": ["Raspberry Pi", "ESP32 CAM", "NodeJS", "OpenCV"],
      "developers": [
        { "id": "141", "name": "Aswin Sreekumar" },
        { "id": "140", "name": "Satish Kumar L" },
        { "id": "144", "name": "Greeshwar R S" },
        { "id": "0", "name": "H Kailash (Associate)" }
      ],
      "cardCoverImage": "https://i.imgur.com/qMuOW2n.png",
      "backgroundImage": "https://i.imgur.com/W2fmJUJ.png",
      "images": [
        "https://i.imgur.com/qMuOW2n.png",
        "https://i.imgur.com/D4bgomy.png",
        "https://i.imgur.com/dLfFv2I.png",
        "https://i.imgur.com/rKWoQWb.png",
        "https://i.imgur.com/pZ2mWGT.png",
        "https://i.imgur.com/HKPX33z.png",
        "https://i.imgur.com/gxk1akO.png",
        "https://i.imgur.com/rTP26Ix.png",
        "https://i.imgur.com/SkCQuLk.png"
      ],
      "quickLinks": {
        "youtubeLink": "",
        "githubLink": "https://github.com/RMI-NITT/Smart-parking-system",
        "otherLink": ""
      },
      "publications": [
        {
          "title": "Winners of Amrita Smart City Hackathon 2021",
          "subtitle": "Amrita Coimbatore | Honeywell Technologies",
          "link": ""
        },
        {
          "title": "",
          "subtitle": "",
          "link": ""
        }
      ]
    },
    {
      "pid": "8",
      "seededIn": "2017",
      "shortName": "Pepper",
      "longName": "Robotic Autonomous Mobile Assistant",
      "duration": "2017 - 2021",
      "shortDesc": "A differential drive robot capable of mapping an indoor environment and navigating through it using SLAM algorithms.",
      "longDesc": [
        {
          "heading": "",
          "para": "Pepper is aimed at being a personal assistant for the user using various artificial intelligent algorithms. Few of the employed algorithms can perform speech recognition, object detection and recognition. A gripper is also present on the robot's chassis that serves object grasping. The robot uses a ROS network to communicate between the sensors, actuators, and the onboard computer (ROS master)."
        },
        {
          "heading": "Robot Design",
          "para": "The robot's chassis was designed using Autocad, and the design was fabricated using acrylic. The chassis can be broadly classified into three layers - the bottom layer contains the battery and driver, the middle layer has the gripper arm, and the top layer includes the onboard computer. Microsoft Kinect is attached to the topmost pedestal. Two high-torque motors with internal rotary encoders are used to move the robot, and a castor wheel provides stability."
        },
        {
          "heading": "Mapping",
          "para": "To navigate an environment optimally, its map is required. Pepper achieves this using the onboard Kinect sensor and the gmapping ROS package. The package uses the Simultaneous Localisation and Mapping Algorithm (SLAM) to generate the map."
        },
        {
          "heading": "Localisation",
          "para": "As the robot's size increases, the drift in the wheels also increases. We use more than one sensor to tackle this problem and put the Kalman filter algorithm to use. The inbuilt encoder performs dead reckoning and obtains the robot's pose. A gyroscope is also used to get the robot's yaw orientation, and these sensor values are used in the Kalman filter to estimate the pose."
        },
        {
          "heading": "Speech Recognition",
          "para": "When the robot detects a voice command from a user, it must first identify the speaker before responding to him. A machine learning algorithm was developed to identify the speaker of a voice sample. The algorithm used was text-independent and was created as a real-time application. The voice samples of the speaker were first trained using the Mel Frequency Cepstral Coefficient (MFCC) Vectors extracted from the training voice data. The voice model of the speaker was thus developed, and the corresponding parameters were saved in the database. This was done for all speakers. When a real-time test sample is detected, the machine extracts the MFCC vectors and compares them with the already saved voice samples. The closest match in the existing database is found; hence, the speaker is recognised."
        },
        {
          "heading": "Object Recognition and Pick up",
          "para": "The bot is trained with 1000 classes of objects using a Convolutional Neural Network (CNN). CNN is a bio-inspired machine learning algorithm whose functions are similar to the eye. The input image is captured using Kinect, and its depth is measured. A robotic arm is mounted on the base of the robot. If the depth is greater than the workspace of the robotic arm, then the robot moves closer to the object. The robotic arm has 3 degrees of freedom, with the gripper possessing 1 DoF. Once the object is recognised, the robot picks it up."
        }
      ],
      "techStack": ["SLAM", "Microsoft Kinect", "ROS Gazebo", "Deep Learning"],
      "developers": [
        { "id": "75", "name": "Adarsh Jagan S" },
        { "id": "74", "name": "Prakash Baskaran" },
        { "id": "0", "name": "Sriharish S" },
        { "id": "84", "name": "Arvind Nataraj" },
        { "id": "86", "name": "Ruthrash Hari" },
        { "id": "81", "name": "Nithin Shrivatsav S" },
        { "id": "88", "name": "Venkata Subramanian Srinivasan" },
        { "id": "100", "name": "Surya M" },
        { "id": "92", "name": "Anirudh Swaminathan" },
        { "id": "95", "name": "Subramanian Krishnan" },
        { "id": "103", "name": "Vidyaa K" },
        { "id": "112", "name": "Deepak S V" },
        { "id": "128", "name": "Loahit K" },
        { "id": "121", "name": "Avinash S" },
        { "id": "126", "name": "Kailash Jagadeesh" },
        { "id": "127", "name": "Hemangani N" },
        { "id": "123", "name": "Shrikumaran P B" }
      ],
      "cardCoverImage": "https://i.imgur.com/QS5TQaF.png",
      "backgroundImage": "https://i.imgur.com/p5bEAmV.png",
      "images": [
        "https://i.imgur.com/QS5TQaF.png",
        "https://i.imgur.com/sXIzEMM.png",
        "https://i.imgur.com/nwmNWUM.png",
        "https://i.imgur.com/rWqcXIM.png"
      ],
      "quickLinks": {
        "youtubeLink": "https://github.com/RMI-NITT/project_pepper",
        "githubLink": "https://youtube.com/playlist?list=PL44ElmNkyTvBqNAVxaPmKnhxJGcgDSsyj",
        "otherLink": ""
      },
      "publications": [
        {
          "title": "",
          "subtitle": "",
          "link": ""
        },
        {
          "title": "",
          "subtitle": "",
          "link": ""
        }
      ]
    },
    {
      "pid": "",
      "seededIn": "",
      "shortName": "",
      "longName": "",
      "duration": "",
      "shortDesc": "",
      "longDesc": [
        {
          "heading": "",
          "para": ""
        },
        {
          "heading": "",
          "para": ""
        },
        {
          "heading": "",
          "para": ""
        }
      ],
      "techStack": ["", "", "", ""],
      "developers": [
        { "id": "", "name": "" },
        { "id": "", "name": "" },
        { "id": "", "name": "" },
        { "id": "", "name": "" }
      ],
      "cardCoverImage": "",
      "backgroundImage": "",
      "images": [],
      "quickLinks": {
        "youtubeLink": "",
        "githubLink": "",
        "otherLink": ""
      },
      "publications": [
        {
          "title": "",
          "subtitle": "",
          "link": ""
        },
        {
          "title": "",
          "subtitle": "",
          "link": ""
        }
      ]
    }
  ]
}
